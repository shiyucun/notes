# 人脸识别

- [人脸识别](#人脸识别)
  - [视频捕捉](#视频捕捉)
  - [面部定位](#面部定位)
  - [主成分分析(Principal Components Analysis, PCA)](#主成分分析principal-components-analysis-pca)
  - [核主成分分析](#核主成分分析)
  - [独立成分分析](#独立成分分析)
  - [识别人脸](#识别人脸)

## 视频捕捉

```python
import numpy as np
import cv2 as cv


cap = cv.VideoCapture(0)  # 打开视频设备
while True:  # 每隔33ms读取依次视频数据并显示
    image = cap.read()[1]
    image = cv.resize(image, None, fx=0.75, fy=0.75,
                      interpolation=cv.INTER_AREA)
    cv.imshow('VideoCapture', image)
    if cv.waitKey(33) == 27:
        break

cap.release()  # 释放视频设备
cv.destroyAllWindows()
```

## 面部定位

```python
import numpy as np
import cv2 as cv

# xml中存放的是训练后的特征池，根据特征值数据创建分类器
face_detector = cv.CascadeClassifier('haar\\face.xml')
eye_detector = cv.CascadeClassifier('haar\\eye.xml')
nose_detector = cv.CascadeClassifier('haar\\nose.xml')

cap = cv.VideoCapture(0)
while True:
    image = cap.read()[1]
    image = cv.resize(image, None, fx=0.75, fy=0.75,
                      interpolation=cv.INTER_AREA)
    # 检测脸、眼睛、鼻子并使用椭圆圈出
    faces = face_detector.detectMultiScale(image, 1.3, 5)
    eyes = eye_detector.detectMultiScale(image, 1.3, 5)
    noses = nose_detector.detectMultiScale(image, 1.3, 5)
    for l, t, w, h in faces:
        a, b = int(w / 2), int(h / 2)
        cv.ellipse(image, (l + a, t + b), (a, b), 0, 0, 360, (255, 0, 255), 2)
    for l, t, w, h in eyes:
        a, b = int(w / 2), int(h / 2)
        cv.ellipse(image, (l + a, t + b), (a, b), 0, 0, 360, (255, 255, 0), 2)
    for l, t, w, h in noses:
        a, b = int(w / 2), int(h / 2)
        cv.ellipse(image, (l + a, t + b), (a, b), 0, 0, 360, (0, 255, 255), 2)
    cv.imshow('VideoCapture', image)

    if cv.waitKey(33) == 27:
        break

cap.release()
cv.destroyAllWindows()
```

## 主成分分析(Principal Components Analysis, PCA)

PCA识别数据中的重要部分，并将其按照重要程度排序。

当需要处理很大维度的特征值时，利用PCA降维，可以在不损失数据重要特征的同时，降低其处理复杂度。

```python
import os
import sys
import numpy as np
import sklearn.decomposition as dc


def make_data():
    a = np.random.normal(size=250)
    b = np.random.normal(size=250)
    c = 2 * a + 3 * b
    d = 4 * a - b
    e = c + 2 * d
    x = np.c_[d, b, e, a, c]
    return x


def train_model(x):
    model = dc.PCA()
    model.fit(x)
    return model


def reduce_model(model, n_components, x):
    model.n_components = n_components
    x = model.fit_transform(x)
    return x


def main(argc, argv, envp):
    x = make_data()
    print(x)
    model = train_model(x)
    variances = model.explained_variance_
    print(variances)
    threshold = 0.8
    useful_indices = np.where(variances > threshold)[0]
    print(useful_indices)
    n_useful = len(useful_indices)
    print(n_useful)
    x = reduce_model(model, n_useful, x)
    print(x)
    return 0


if __name__ == '__main__':
    sys.exit(main(len(sys.argv), sys.argv, os.environ))
```

## 核主成分分析

```python
import os
import sys
import platform
import numpy as np
import sklearn.datasets as sd
import sklearn.decomposition as dc
import matplotlib.pyplot as mp


def make_data():
    np.random.seed(7)
    x, y = sd.make_circles(n_samples=500, factor=0.2, noise=0.04)
    return x, y


def pca(x):
    model = dc.PCA()
    x = model.fit_transform(x)
    return x


def kpca(x):
    model = dc.KernelPCA(kernel='rbf', fit_inverse_transform=True,
                         gamma=10)
    x = model.fit_transform(x)
    return model, x


def ikpca(model, x):
    x = model.inverse_transform(x)
    return x


def init_original():
    mp.gcf().set_facecolor(np.ones(3) * 240 / 255)
    mp.subplot(221)
    mp.title('Original Samples', fontsize=16)
    mp.xlabel('x', fontsize=12)
    mp.ylabel('y', fontsize=12)
    mp.tick_params(which='both', top=True, right=True,
                   labelright=True, labelsize=10)
    mp.grid(linestyle=':')


def draw_chart(x, y):
    mp.scatter(x[y == 0][:, 0], x[y == 0][:, 1], c='dodgerblue',
               alpha=0.5, s=80, label='Class 0')
    mp.scatter(x[y == 1][:, 0], x[y == 1][:, 1], c='Orangered',
               alpha=0.5, s=80, label='Class 1')
    mp.legend()


def init_pca():
    mp.gcf().set_facecolor(np.ones(3) * 240 / 255)
    mp.subplot(222)
    mp.title('PCA Samples', fontsize=16)
    mp.xlabel('x', fontsize=12)
    mp.ylabel('y', fontsize=12)
    mp.tick_params(which='both', top=True, right=True,
                   labelright=True, labelsize=10)
    mp.grid(linestyle=':')


def init_kpca():
    mp.subplot(223)
    mp.title('KPCA Samples', fontsize=16)
    mp.xlabel('x', fontsize=12)
    mp.ylabel('y', fontsize=12)
    mp.tick_params(which='both', top=True, right=True,
                   labelright=True, labelsize=10)
    mp.grid(linestyle=':')


def init_ikpca():
    mp.subplot(224)
    mp.title('Inverse KPCA Samples', fontsize=16)
    mp.xlabel('x', fontsize=12)
    mp.ylabel('y', fontsize=12)
    mp.tick_params(which='both', top=True, right=True,
                   labelright=True, labelsize=10)
    mp.grid(linestyle=':')


def draw_chart(x, y):
    mp.scatter(x[y == 0][:, 0], x[y == 0][:, 1], c='dodgerblue',
               alpha=0.5, s=80, label='Class 0')
    mp.scatter(x[y == 1][:, 0], x[y == 1][:, 1], c='Orangered',
               alpha=0.5, s=80, label='Class 1')
    mp.legend()


def show_chart():
    mng = mp.get_current_fig_manager()
    if 'Windows' in platform.system():
        mng.window.state('zoomed')
    else:
        mng.resize(*mng.window.maxsize())
    mp.tight_layout()
    mp.show()


def main(argc, argv, envp):
    x, y = make_data()
    pca_x = pca(x)
    model, kpca_x = kpca(x)
    ikpca_x = ikpca(model, kpca_x)
    init_original()
    draw_chart(x, y)
    init_pca()
    draw_chart(pca_x, y)
    init_kpca()
    draw_chart(kpca_x, y)
    init_ikpca()
    draw_chart(ikpca_x, y)
    show_chart()
    return 0


if __name__ == '__main__':
    sys.exit(main(len(sys.argv), sys.argv, os.environ))
```

## 独立成分分析

```python
import os
import sys
import platform
import numpy as np
import sklearn.decomposition as dc
import matplotlib.pyplot as mp


def read_data(filename):
    x = np.loadtxt(filename)
    return x


def ica(x):
    model = dc.FastICA(n_components=x.shape[1])
    x = model.fit_transform(x)
    return x


def init_original():
    mp.gcf().set_facecolor(np.ones(3) * 240 / 255)
    mp.subplot(211)
    mp.title('Original', fontsize=16)
    mp.xlabel('Time', fontsize=12)
    mp.ylabel('Signal', fontsize=12)
    mp.tick_params(which='both', top=True, right=True,
                   labelright=True, labelsize=10)
    mp.grid(linestyle=':')


def init_ica():
    mp.subplot(212)
    mp.title('ICA', fontsize=16)
    mp.xlabel('Time', fontsize=12)
    mp.ylabel('Signal', fontsize=12)
    mp.tick_params(which='both', top=True, right=True,
                   labelright=True, labelsize=10)
    mp.grid(linestyle=':')


def draw_chart(x):
    x = x.T
    for i, component in enumerate(x):
        mp.plot(component, label='Component %d' % (i + 1))
    #mp.plot(x.sum(axis=0), c='black', label='Mixture')
    mp.legend()


def show_chart():
    mng = mp.get_current_fig_manager()
    if 'Windows' in platform.system():
        mng.window.state('zoomed')
    else:
        mng.resize(*mng.window.maxsize())
    mp.tight_layout()
    mp.show()


def main(argc, argv, envp):
    x = read_data('signals.txt')
    ica_x = ica(x)
    init_original()
    draw_chart(x)
    init_ica()
    draw_chart(ica_x)
    show_chart()
    return 0

if __name__ == '__main__':
    sys.exit(main(len(sys.argv), sys.argv, os.environ))
```

## 识别人脸

```python
import os
import sys
import numpy as np
import cv2 as cv
import sklearn.preprocessing as sp


def search_faces(directory):
    if not os.path.isdir(directory):
        raise IOError("The directory '" + directory + "' doesn't exist!")
    faces = {}
    for curdir, subdirs, files in os.walk(directory):
        for jpeg in (file for file in files if file.endswith('.jpg')):
            path = os.path.join(curdir, jpeg)
            label = path.split(os.path.sep)[-2]
            if label not in faces:
                faces[label] = []
            faces[label].append(path)
    return faces


def train_codec(labels):
    codec = sp.LabelEncoder()
    codec.fit(labels)
    return codec


def load_detectors():
    face_detector = cv.CascadeClassifier('haar\\face.xml')
    return face_detector


def read_image(filename):
    image = cv.imread(filename)
    return image


def bgr2gray(image):
    image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)
    return image


def detect_regions(detector, image):
    regions = detector.detectMultiScale(image, 1.1, 2, minSize=(100, 100))
    return regions


def encode(codec, label):
    code = int(codec.transform([label])[0])
    return code


def show_image(title, image):
    cv.imshow(title, image)


def decode(codec, code):
    label = codec.inverse_transform(code)
    return label


def wait_escape(delay=0):
    return cv.waitKey(delay) == 27


def read_data(directory):
    faces = search_faces(directory)
    codec = train_codec(list(faces.keys()))
    face_detector = load_detectors()
    x, y, z = [], [], []
    for label, filenames in faces.items():
        for filename in filenames:
            print(filename, '->', label)
            original = read_image(filename)
            gray = bgr2gray(original)
            faces = detect_regions(face_detector, gray)
            for l, t, w, h in faces:
                x.append(gray[t:t + h, l:l + w])
                y.append(encode(codec, label))
                a, b = int(w / 2), int(h / 2)
                cv.ellipse(original, (l + a, t + b), (a, b),
                           0, 0, 360, (255, 0, 255), 2)
                z.append(original)
    y = np.array(y)
    return codec, x, y, z


def train_model(x, y):
    model = cv.face.LBPHFaceRecognizer_create()
    model.train(x, y)
    return model


def pred_model(model, x):
    y = []
    for face in x:
        y.append(model.predict(face)[0])
    return y


def show_labels(codec, codes, pred_codes, images):
    escape = False
    while not escape:
        for code, pred_code, image in zip(codes, pred_codes, images):
            cv.putText(image, '{} {} {}'.format(
                decode(codec, code),
                '==' if code == pred_code else '!=',
                decode(codec, pred_code)), (10, 60),
                cv.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 6)
            show_image('Recognizing Face...', image)
            if wait_escape(1000):
                escape = True
                break


def main(argc, argv, envp):
    codec, train_x, train_y, train_z = read_data('faces\\training')
    _, test_x, test_y, test_z = read_data('faces\\testing')
    model = train_model(train_x, train_y)
    pred_test_y = pred_model(model, test_x)
    show_labels(codec, test_y, pred_test_y, test_z)
    return 0


if __name__ == '__main__':
    sys.exit(main(len(sys.argv), sys.argv, os.environ))
```
