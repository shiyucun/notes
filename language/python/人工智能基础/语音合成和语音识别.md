# 语音识别和语音合成

- [语音识别和语音合成](#语音识别和语音合成)
  - [读取音频数据](#读取音频数据)
  - [将音频从时间域转换到频域](#将音频从时间域转换到频域)
  - [合成音频信号](#合成音频信号)
  - [梅尔频率倒谱系数](#梅尔频率倒谱系数)
  - [语音识别](#语音识别)

## 读取音频数据

音频文件可以通过`scipy.io.wavfile`中的`read`函数来读取。

该函数返回采样频率和信号采样值，该值在存储时会乘以2^15并取整。

```python
import numpy as np
import scipy.io.wavfile as wf
import matplotlib.pyplot as mp

sample_rate, sigs = wf.read('signal.wav')  # 读取音频文件
sigs = sigs[:30] / 2 ** 15  # 取前30个数据点，并将整型数据转换为浮点数
times = np.arange(30) / sample_rate  # 采样频率转换为时间点

mp.gcf().set_facecolor(np.ones(3) * 240 / 255)
mp.title('Audio Signal', fontsize=20)
mp.xlabel('Time', fontsize=14)
mp.ylabel('Signal', fontsize=14)
mp.tick_params(labelsize=10)
mp.grid(linestyle=':')
mp.plot(times, sigs, c='dodgerblue', label='Signal', zorder=0)
mp.scatter(times, sigs, edgecolor='orangered',
           facecolor='white', s=80, label='Sample', zorder=1)
mp.legend()
mp.show()
```

## 将音频从时间域转换到频域

```python
import numpy as np
import numpy.fft as nf
import scipy.io.wavfile as wf
import matplotlib.pyplot as mp

sample_rate, sigs = wf.read('freq.wav')
sigs = sigs / 2 ** 15
times = np.arange(len(sigs)) / sample_rate
freqs = nf.fftfreq(sigs.size, d=1 / sample_rate)
ffts = nf.fft(sigs)  # 快速傅里叶变换
pows = np.abs(ffts)

mp.gcf().set_facecolor(np.ones(3) * 240 / 255)
mp.subplot(121)
mp.title('Time Domain', fontsize=16)
mp.xlabel('Time', fontsize=12)
mp.ylabel('Signal', fontsize=12)
mp.tick_params(labelsize=10)
mp.grid(linestyle=':')
mp.plot(times, sigs, c='dodgerblue', label='Signal')
mp.legend()
mp.subplot(122)
mp.title('Frequency Domain', fontsize=16)
mp.xlabel('Frequency', fontsize=12)
mp.ylabel('Power', fontsize=12)
mp.tick_params(labelsize=10)
mp.grid(linestyle=':')
mp.plot(freqs[freqs >= 0], pows[freqs >= 0], c='orangered', label='Power')
mp.legend()
mp.show()
```

## 合成音频信号

```python
import json
import numpy as np
import scipy.io.wavfile as wf

with open('12.json', 'r') as f:  # 加载钢琴按键频率文件
    freqs = json.loads(f.read())

tones = [
    ('G5', 1.5), ('A5', 0.5), ('G5', 1.5), ('E5', 0.5), ('D5', 0.5),
    ('E5', 0.25), ('D5', 0.25), ('C5', 0.5), ('A4', 0.5), ('C5', 0.75)]

sample_rate = 44100

music = np.empty(shape=1)
for tone, duration in tones:
    times = np.linspace(0, duration, duration * sample_rate)
    sound = np.sin(2 * np.pi * freqs[tone] * times)
    music = np.append(music, sound)
music *= 2 ** 15
music = music.astype(np.int16)

wf.write('music.wav', sample_rate, music)
```

## 梅尔频率倒谱系数

```python
import numpy as np
import scipy.io.wavfile as wf
import python_speech_features as sf
import matplotlib.pyplot as mp

sample_rate, sigs = wf.read('freq.wav')

mfcc = sf.mfcc(sigs, sample_rate)  # 转换

mp.matshow(mfcc.T, cmap='gist_rainbow')
mp.gcf().set_facecolor(np.ones(3) * 240 / 255)
mp.title('MFCC', fontsize=20)
mp.xlabel('Sample', fontsize=14)
mp.ylabel('Feature', fontsize=14)
ax = mp.gca()
ax.xaxis.set_major_locator(mp.MultipleLocator(20))
ax.xaxis.set_minor_locator(mp.MultipleLocator(10))
ax.yaxis.set_major_locator(mp.MultipleLocator(0.5))
ax.yaxis.set_minor_locator(mp.MultipleLocator(0.25))
mp.tick_params(which='both', top='False', labeltop='False',
               labelbottom=True, labelsize=10)
mp.show()
```

## 语音识别

```python
import os
import warnings
import numpy as np
import scipy.io.wavfile as wf
import python_speech_features as sf
import hmmlearn.hmm as hl

warnings.filterwarnings('ignore', category=DeprecationWarning)
np.seterr(all='ignore')

def search_speeches(directory, speeches):
    directory = os.path.normpath(directory)
    for entry in os.listdir(directory):
        label = directory[directory.rfind(os.path.sep) + 1:]
        path = os.path.join(directory, entry)
        if os.path.isdir(path):
            search_speeches(path, speeches)
        elif os.path.isfile(path) and path.endswith('.wav'):
            if label not in speeches:
                speeches[label] = []
            speeches[label].append(path)

# 查找文件(训练数据)
train_speeches = {}
search_speeches('training', train_speeches)
# 读取训练数据
train_x, train_y = [], []
for label, filenames in train_speeches.items():
    mfccs = np.array([])
    for filename in filenames:
        sample_rate, sigs = wf.read(filename)
        mfcc = sf.mfcc(sigs, sample_rate)
        if len(mfccs) == 0:
            mfccs = mfcc
        else:
            mfccs = np.append(mfccs, mfcc, axis=0)
    train_x.append(mfccs)
    train_y.append(label)
# 针对每一组数据训练model(隐马尔科夫模型)
models = {}
for mfccs, label in zip(train_x, train_y):
    model = hl.GaussianHMM(n_components=4, covariance_type='diag', n_iter=1000)
    models[label] = model.fit(mfccs)
# 查找文件(测试数据)
test_speeches = {}
search_speeches('testing', test_speeches)
# 读取测试数据
test_x, test_y = [], []
for label, filenames in test_speeches.items():
    mfccs = np.array([])
    for filename in filenames:
        sample_rate, sigs = wf.read(filename)
        mfcc = sf.mfcc(sigs, sample_rate)
        if len(mfccs) == 0:
            mfccs = mfcc
        else:
            mfccs = np.append(mfccs, mfcc, axis=0)
    test_x.append(mfccs)
    test_y.append(label)
# 将测试数据输入每个model，得到给出的评分，评分最高的即为识别出来的类
pred_test_y = []
for mfccs in test_x:
    best_score, best_label = None, None
    for label, model in models.items():
        score = model.score(mfccs)
        if (best_score is None) or (best_score < score):
            best_score, best_label = score, label
    pred_test_y.append(best_label)
print(test_y)
print(pred_test_y)
```
