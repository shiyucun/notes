# 推荐引擎

- [推荐引擎](#推荐引擎)
  - [流水管线](#流水管线)
    - [python中map的使用](#python中map的使用)
    - [python中reduce的使用](#python中reduce的使用)
    - [函数级联](#函数级联)
  - [利用流水管线串联特征选择器和分类器](#利用流水管线串联特征选择器和分类器)
  - [寻找最近邻(Find Nearest Neighbors，FNN)](#寻找最近邻find-nearest-neighborsfnn)
  - [KNN分类](#knn分类)
  - [KNN回归](#knn回归)
  - [欧氏距离分数(可用于判断相似度)](#欧氏距离分数可用于判断相似度)
  - [皮尔逊距离分数](#皮尔逊距离分数)

## 流水管线

### python中map的使用

```python
def f1(x):
    return x + 3

a = [1, 2, 3]
b = list(map(f1, a))
print(b)

c = list(map(lambda x: x + 3, a))
print(c)

# [4, 5, 6]
# [4, 5, 6]
```

### python中reduce的使用

```python
import functools

def f1(x, y):
    print('f1:', x, y)
    return x + y

a = [1, 2, 3, 4]
b = functools.reduce(f1, a)
print(b)

c = functools.reduce(lambda x,y:x+y, a)
print(c)

# f1: 1 2
# f1: 3 3
# f1: 6 4
# 10
# 10
```

### 函数级联

用一个函数的返回值做为另一个函数的参数。

```python
import functools

def f1(a):
    return map(lambda x: x + 3, a)

def f2(a):
    return map(lambda x: x * 6, a)

def f3(a):
    return map(lambda x: x - 9, a)

def pipeline(*fs):
    return functools.reduce(
        lambda fa, fb: lambda x: fa(fb(x)), fs)

a = [1, 2, 3]
print(list(f3(f2(f1(a)))))

fc = functools.reduce(
    lambda fa, fb: lambda x: fa(fb(x)), [f3, f2, f1])
c = list(fc(a))
print(c)

print(list(pipeline(f3, f2, f1)(a)))

# 15
# 15
# 15
# 15
```

```python
import functools

def f1(a):
    return map(lambda x: x + 3, a)

def f2(a):
    return map(lambda x: x * 6, a)

def f3(a):
    return map(lambda x: x - 9, a)

def pipeline(*fs):
    return functools.reduce(
        lambda fa, fb: lambda x: fa(fb(x)), fs)

a = [1, 2, 3]
print(list(f3(f2(f1(a)))))

fc = functools.reduce(
    lambda fa, fb: lambda x: fa(fb(x)), [f3, f2, f1])
c = list(fc(a))
print(c)

print(list(pipeline(f3, f2, f1)(a)))

# [15, 21, 27]
# [15, 21, 27]
# [15, 21, 27]
```

## 利用流水管线串联特征选择器和分类器

```python
import numpy as np
import sklearn.datasets as sd
import sklearn.feature_selection as fs
import sklearn.ensemble as se
import sklearn.pipeline as sp
import sklearn.model_selection as ms
import matplotlib.pyplot as mp


x, y = sd.samples_generator.make_classification(
    n_informative=4, n_features=20, n_redundant=0,
    random_state=5)  # 在线加载数据

skb = fs.SelectKBest(fs.f_regression, k=5)  # 选择器，选择影响最大的5个特征
rfc = se.RandomForestClassifier(n_estimators=25, max_depth=4)  # 分类器

model = sp.Pipeline([('selector', skb), ('classifier', rfc)])  # 创建管道
print(ms.cross_val_score(model, x, y, cv=10, scoring='f1_weighted').mean())

model.set_params(selector__k=2, classifier__n_estimators=10)  # 修改选择器和分类器的参数
print(ms.cross_val_score(model, x, y, cv=10, scoring='f1_weighted').mean())
model.fit(x, y)

selected_mask = model.named_steps['selector'].get_support()
selected_indices = np.arange(x.shape[1])[selected_mask]
x = x[:, selected_indices]
model.fit(x, y)

l, r, h = x[:, 0].min() - 1, x[:, 0].max() + 1, 0.005
b, t, v = x[:, 1].min() - 1, x[:, 1].max() + 1, 0.005
grid_x = np.meshgrid(np.arange(l, r, h), np.arange(b, t, v))
flat_x = np.c_[grid_x[0].ravel(), grid_x[1].ravel()]
flat_y = model.predict(flat_x)
grid_y = flat_y.reshape(grid_x[0].shape)

mp.gcf().set_facecolor(np.ones(3) * 240 / 255)
mp.title('Selector-Classifier Pipeline', fontsize=20)
mp.xlabel('x', fontsize=14)
mp.ylabel('y', fontsize=14)
ax = mp.gca()
ax.xaxis.set_major_locator(mp.MultipleLocator())
ax.xaxis.set_minor_locator(mp.MultipleLocator(0.5))
ax.yaxis.set_major_locator(mp.MultipleLocator())
ax.yaxis.set_minor_locator(mp.MultipleLocator(0.5))
ax.tick_params(labelsize=10)
mp.pcolormesh(grid_x[0], grid_x[1], grid_y, cmap='Dark2')
mp.xlim(grid_x[0].min(), grid_x[0].max())
mp.ylim(grid_x[1].min(), grid_x[1].max())
mp.scatter(x[:, 0], x[:, 1], c=y, cmap='cool', s=80)
mp.show()

# 0.771793206793
# 0.744154179154
```

## 寻找最近邻(Find Nearest Neighbors，FNN)

```python
import numpy as np
import sklearn.neighbors as sn
import matplotlib.pyplot as mp
import matplotlib.patches as mc

train_x = np.array([
    [3.0, 7.0], [2.3, 9.0], [1.7, 9.0], [1.0, 7.0], [1.0, 5.0], [1.7, 3.0],
    [3.0, 1.0], [4.3, 3.0], [5.0, 5.0], [5.0, 7.0], [4.3, 9.0], [3.7, 9.0]])

model = sn.NearestNeighbors(n_neighbors=3, algorithm='ball_tree')  # 寻找最近的三个点，'ball_tree'表明使用欧几里德计算方法
model.fit(train_x)

test_x = np.array([
    [2.3, 8.3], [1.7, 7.5], [1.7, 6.5], [2.3, 5.0], [2.8, 4.7],
    [3.0, 5.5], [3.2, 4.7], [3.7, 5.0], [4.3, 7.5], [4.3, 6.5],
    [3.7, 8.3], [2.3, 4.0], [3.0, 2.0], [3.7, 4.0]])
nn_distances, nn_indices = model.kneighbors(test_x)

mp.gcf().set_facecolor(np.ones(3) * 240 / 255)
mp.title('Find Nearest Neighbors', fontsize=20)
mp.xlabel('x', fontsize=14)
mp.ylabel('y', fontsize=14)
ax = mp.gca()
ax.xaxis.set_major_locator(mp.MultipleLocator())
ax.yaxis.set_major_locator(mp.MultipleLocator())
ax.tick_params(labelsize=10)
mp.grid(linestyle=':')
mp.scatter(train_x[:, 0], train_x[:, 1], c='k', zorder=2)
cs = mp.get_cmap('gist_rainbow', len(nn_indices))(range(len(nn_indices)))
for i, (x, nn_index) in enumerate(zip(test_x, nn_indices)):
    mp.gca().add_patch(mc.Polygon(
        train_x[nn_index], ec='none', fc=cs[i], alpha=0.2, zorder=0))
    mp.scatter(x[0], x[1], c=cs[i], s=80, zorder=1)
mp.show()
```

## KNN分类

根据一组已知分类的样本，寻找距离未知分类样本最近的N个邻居样本，取其中多数样本的分类作为该未知样本的分类。

```python
import numpy as np
import sklearn.neighbors as sn
import matplotlib.pyplot as mp

train_x, train_y = [], []
with open('knn.txt', 'r') as f:
    for line in f.readlines():
        data = [float(substr) for substr in
                line.split(',')]
        train_x.append(data[:-1])
        train_y.append(data[-1])
train_x = np.array(train_x)
train_y = np.array(train_y, dtype=int)

model = sn.KNeighborsClassifier(n_neighbors=10, weights='distance')
model.fit(train_x, train_y)

l, r, h = train_x[:, 0].min() - 1, train_x[:, 0].max() + 1, 0.005
b, t, v = train_x[:, 1].min() - 1, train_x[:, 1].max() + 1, 0.005
grid_x = np.meshgrid(np.arange(l, r, h), np.arange(b, t, v))
flat_x = np.c_[grid_x[0].ravel(), grid_x[1].ravel()]
flat_y = model.predict(flat_x)
grid_y = flat_y.reshape(grid_x[0].shape)
test_x = np.array([
    [2.2, 6.2],
    [3.6, 1.8],
    [4.5, 3.6]])
pred_test_y = model.predict(test_x)
_, nn_indices = model.kneighbors(test_x)

mp.gcf().set_facecolor(np.ones(3) * 240 / 255)
mp.title('KNN Classification', fontsize=20)
mp.xlabel('x', fontsize=14)
mp.ylabel('y', fontsize=14)
ax = mp.gca()
ax.xaxis.set_major_locator(mp.MultipleLocator())
ax.xaxis.set_minor_locator(mp.MultipleLocator(0.5))
ax.yaxis.set_major_locator(mp.MultipleLocator())
ax.yaxis.set_minor_locator(mp.MultipleLocator(0.5))
mp.tick_params(labelsize=10)
mp.pcolormesh(grid_x[0], grid_x[1], grid_y, cmap='brg')
mp.xlim(grid_x[0].min(), grid_x[0].max())
mp.ylim(grid_x[1].min(), grid_x[1].max())
classes = np.unique(train_y)
classes.sort()
cs = mp.get_cmap('RdYlBu', len(classes))(classes)
mp.scatter(train_x[:, 0], train_x[:, 1], c=cs[train_y], s=60)
mp.scatter(test_x[:, 0], test_x[:, 1], marker='D', c=cs[pred_test_y], s=60)
for nn_index, y, in zip(nn_indices, pred_test_y):
    mp.scatter(train_x[nn_index, 0], train_x[nn_index, 1], marker='D',
               edgecolor=cs[np.ones_like(nn_index) * y],
               facecolor='none', linewidth=2, s=180)
mp.show()
```

## KNN回归

在待求输入附近寻找k个最近的训练样本邻居，将其输出取平均值(可以用距离作为加权)作为待求输入的回归值。

```python
import numpy as np
import sklearn.neighbors as sn
import matplotlib.pyplot as mp

train_x = 10 * np.random.rand(100, 1) - 5
train_y = np.sinc(train_x).ravel()

model = sn.KNeighborsRegressor(n_neighbors=10, weights='distance')
model.fit(train_x, train_y)

test_x = np.linspace(-5, 5, 10000).reshape(-1, 1)
pred_test_y = model.predict(test_x)

mp.gcf().set_facecolor(np.ones(3) * 240 / 255)
mp.title('KNN Regression', fontsize=20)
mp.xlabel('x', fontsize=14)
mp.ylabel('y', fontsize=14)
ax = mp.gca()
ax.xaxis.set_major_locator(mp.MultipleLocator())
ax.xaxis.set_minor_locator(mp.MultipleLocator(0.5))
ax.yaxis.set_major_locator(mp.MultipleLocator(0.2))
ax.yaxis.set_minor_locator(mp.MultipleLocator(0.1))
mp.tick_params(labelsize=10)
mp.grid(linestyle=':')
mp.scatter(train_x, train_y, c='dodgerblue', s=60, label='Training')
mp.plot(test_x, pred_test_y, c='orangered', label='Testing')
mp.legend()
mp.show()
```

## 欧氏距离分数(可用于判断相似度)

假设有两个点：a(x1, y1)、b(x2, y2)，则：

- `欧氏距离 = sqrt((x1-x2)^2 + (y1-y2)^2)`
- `欧式距离分数 = 1 / (1 + 欧式距离)`

欧氏距离分数是一个介于0~1之间的浮点数，越接近于1越相似，越接近于0，相似程度越低。

```python
import json
import numpy as np

with open('ratings.json', 'r') as f:
    ratings = json.loads(f.read())
users, scmat = list(ratings.keys()), []
for user1 in users:
    scrow = []
    for user2 in users:
        movies = set()
        for movie in ratings[user1]:
            if movie in ratings[user2]:
                movies.add(movie)
        if len(movies) == 0:
            score = 0
        else:
            x, y = [], []
            for movie in movies:
                x.append(ratings[user1][movie])
                y.append(ratings[user2][movie])
            x = np.array(x)
            y = np.array(y)
            score = 1 / (
                1 + np.sqrt(((x - y) ** 2).sum()))
        scrow.append(score)
    scmat.append(scrow)
users = np.array(users)
scmat = np.array(scmat)
for scrow in scmat:
    print(' '.join(
        '{:>5.2f}'.format(score) for score in scrow))
```

## 皮尔逊距离分数

皮尔逊距离分数就是两个向量的相关系数，即相关性矩阵辅对角线上的值。

两个变量之间的皮尔逊相关系数定义为两个变量之间的协方差和标准差的商。

```python
import json
import numpy as np

with open('ratings.json', 'r') as f:
    ratings = json.loads(f.read())
users, scmat = list(ratings.keys()), []
for user1 in users:
    scrow = []
    for user2 in users:
        movies = set()
        for movie in ratings[user1]:
            if movie in ratings[user2]:
                movies.add(movie)
        if len(movies) == 0:
            score = 0
        else:
            x, y = [], []
            for movie in movies:
                x.append(ratings[user1][movie])
                y.append(ratings[user2][movie])
            x = np.array(x)
            y = np.array(y)
            score = np.corrcoef(x, y)[0, 1]  # 计算皮尔逊距离分数
        scrow.append(score)
    scmat.append(scrow)
users = np.array(users)
scmat = np.array(scmat)
for scrow in scmat:
    print(' '.join('{:>5.2f}'.format(score) for score in scrow))
```
