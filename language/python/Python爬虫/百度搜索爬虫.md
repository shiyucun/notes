
# 百度搜索爬虫

- [百度搜索爬虫](#百度搜索爬虫)
  - [python2实现](#python2实现)
  - [python3实现](#python3实现)

## python2实现

```python
# -*- coding:utf-8 -*-
import urllib
import urllib2

# https://www.baidu.com/s?wd=python
ua_headers = {
    "User-Agent": "Mozilla/5.0 (X11; Ubuntu; linux x86_64; rv:57.0) Gecko/20100101 Firefox/57.0"}
# 用户输入
url = "http://www.baidu.com/s?"
keyword = raw_input(u"Search:")
wd = {"wd": keyword}
wd = urllib.urlencode(wd)  # 'wd=keyword'
fullUrl = url + wd
print(fullUrl)
# 向百度服务器发送get请求
request = urllib2.Request(fullUrl, headers=ua_headers)
response = urllib2.urlopen(request)
# 写到文件中
html = response.read()
with open("baidusearch.html", "w") as f:
    f.writelines(html)
# 获取response状态码
print(response.getcode())
```

## python3实现

```python
import urllib
from urllib import request

# 使用百度进行搜索时url格式：https://www.baidu.com/s?wd=python
# user-agent
ua_headers = {
    "User-Agent": "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:57.0) Gecko/20100101 Firefox/57.0"}
# 构造get方法的链接
url = "http://www.baidu.com/s?"
# 用户输入
keyword = input(u"Search:")
wd = {"wd": keyword}
# wd需要进行一次编码用于与url连接得到完整的url
wd = urllib.parse.urlencode(wd)  # 'wd=keyword'
fullUrl = url + wd
print(fullUrl)  # http://www.baidu.com/s?wd=python
# 对百度服务器发起get请求
req = request.Request(fullUrl, headers=ua_headers)
response = request.urlopen(req)
html = response.read().decode("utf-8")
# 写到文件中
with open("baidusearch.html", "wb") as f:
    f.write(html.encode())
# 打印response状态码
print(response.getcode())
```
